{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download GDEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20181101.export.CSV.zip']\n",
      "20181101.export.CSV.zip\n",
      "extracting,\n",
      "done\n",
      "parsing,\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "\n",
    "gdelt_base_url = 'http://data.gdeltproject.org/events/'\n",
    "\n",
    "# get the list of all the links on the gdelt file page\n",
    "page = requests.get(gdelt_base_url+'index.html')\n",
    "doc = lh.fromstring(page.content)\n",
    "link_list = doc.xpath(\"//*/ul/li/a/@href\")\n",
    "\n",
    "# separate out those links that begin with four digits\n",
    "file_list = [x for x in link_list if str.isdigit(x[0:4])] # mengambil file x yang string are digits 4 baris pertama\n",
    "file_list2 = file_list[0:10]   # mengambil file di list GDELT yang 2 baris pertama\n",
    "print(file_list2)\n",
    "\n",
    "infilecounter = 0\n",
    "outfilecounter = 0\n",
    "\n",
    "import os.path\n",
    "import urllib\n",
    "import zipfile\n",
    "import glob\n",
    "import operator\n",
    "\n",
    "local_path = 'D:/GDELT/'\n",
    "\n",
    "fips_country_code = 'ID'\n",
    "\n",
    "for compressed_file in file_list2[infilecounter:]:\n",
    "    print(compressed_file)\n",
    "\n",
    "    # if we dont have the compressed file stored locally, go get it. Keep trying if necessary.\n",
    "    while not os.path.isfile(local_path + compressed_file):\n",
    "        print('downloading, '),\n",
    "        urllib.request.urlretrieve(url=gdelt_base_url + compressed_file,\n",
    "                           filename=local_path + compressed_file)\n",
    "        print('done')\n",
    "\n",
    "    # extract the contents of the compressed file to a temporary directory\n",
    "    print('extracting,'),\n",
    "    z = zipfile.ZipFile(file=local_path + compressed_file, mode='r')\n",
    "    z.extractall(path=local_path + 'tmp/')\n",
    "    print('done')\n",
    "\n",
    "    # parse each of the csv files in the working directory,\n",
    "    print('parsing,'),\n",
    "    for infile_name in glob.glob(local_path + 'tmp/*'):\n",
    "        outfile_name = local_path + 'country/' + fips_country_code + '%04i.tsv' % outfilecounter\n",
    "\n",
    "        # open the infile and outfile\n",
    "        with open(infile_name, encoding='utf8', mode='r') as infile, open(outfile_name, mode='w') as outfile:\n",
    "            for line in infile:\n",
    "                # extract lines with our interest country code\n",
    "                if fips_country_code in operator.itemgetter(51, 37, 44)(line.split('\\t')):\n",
    "                    outfile.write(line)\n",
    "            outfilecounter += 1\n",
    "\n",
    "        # delete the temporary file\n",
    "        os.remove(infile_name)\n",
    "    infilecounter += 1\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICKING  DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/GDELT/country\\\\ID0000.tsv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "local_path = 'D:/GDELT/'\n",
    "fips_country_code = 'ID'\n",
    "# Get the GDELT field names from a helper file\n",
    "colnames = pd.read_excel('CSV.header.fieldids.xlsx', sheetname='Sheet1',\n",
    "                         index_col='Column ID', usecols=1)['Field Name']\n",
    "# print (colnames)\n",
    "# Build DataFrames from each of the intermediary files\n",
    "files = glob.glob(local_path + 'country/' + fips_country_code + '*')\n",
    "DFlist = []\n",
    "for active_file in files:\n",
    "    print (files)\n",
    "    DFlist.append(pd.read_csv(active_file, sep='\\t', header=None, dtype=str,\n",
    "                              names=colnames, index_col=['GLOBALEVENTID']))\n",
    "    break\n",
    "\n",
    "# Merge the file-based dataframes and save a pickle\n",
    "DF = pd.concat(DFlist)\n",
    "DF.to_pickle(local_path + 'backupsmall' + fips_country_code + '.pickle')\n",
    "\n",
    "# once everythin is safely stored away, remove the temporary files\n",
    "# for active_file in files:\n",
    "#     os.remove(active_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Data dalam Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID0000.tsv', 'ID0001.tsv', 'ID0002.tsv', 'ID0003.tsv', 'ID0004.tsv', 'ID0005.tsv', 'ID0006.tsv', 'ID0007.tsv', 'ID0008.tsv', 'ID0009.tsv']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "folder_id = 'D:/GDELT/country/'\n",
    "files = [f for f in listdir(folder_id) if isfile(join(folder_id, f))]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>796649358</th>\n",
       "      <th>20171023</th>\n",
       "      <th>201710</th>\n",
       "      <th>2017</th>\n",
       "      <th>2017.8027</th>\n",
       "      <th>BUS</th>\n",
       "      <th>CORPORATION</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>ID.2</th>\n",
       "      <th>4.1</th>\n",
       "      <th>Manila, Manila, Philippines.1</th>\n",
       "      <th>RP.1</th>\n",
       "      <th>RPD9.1</th>\n",
       "      <th>14.6042.1</th>\n",
       "      <th>120.982.1</th>\n",
       "      <th>-2437894.1</th>\n",
       "      <th>20181023</th>\n",
       "      <th>https://www.dealstreetasia.com/stories/chinese-fintech-lenders-philippines-109510/</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>796650128</td>\n",
       "      <td>20181023</td>\n",
       "      <td>201810</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.8027</td>\n",
       "      <td>AFR</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>AFR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Komodo, Indonesia (general), Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID00</td>\n",
       "      <td>-8.58333</td>\n",
       "      <td>119.500</td>\n",
       "      <td>-2683074</td>\n",
       "      <td>20181023</td>\n",
       "      <td>https://www.escape.com.au/news/better-than-bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>796650297</td>\n",
       "      <td>20181023</td>\n",
       "      <td>201810</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.8027</td>\n",
       "      <td>BUS</td>\n",
       "      <td>INDUSTRY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Gudang, Jawa Tengah, Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID07</td>\n",
       "      <td>-6.71010</td>\n",
       "      <td>110.947</td>\n",
       "      <td>10171924</td>\n",
       "      <td>20181023</td>\n",
       "      <td>https://www.dealstreetasia.com/stories/indones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>796650336</td>\n",
       "      <td>20181023</td>\n",
       "      <td>201810</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.8027</td>\n",
       "      <td>BUS</td>\n",
       "      <td>ENTREPRENEUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10171924</td>\n",
       "      <td>4</td>\n",
       "      <td>Gudang, Jawa Tengah, Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID07</td>\n",
       "      <td>-6.71010</td>\n",
       "      <td>110.947</td>\n",
       "      <td>10171924</td>\n",
       "      <td>20181023</td>\n",
       "      <td>https://www.dealstreetasia.com/stories/indones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>796651934</td>\n",
       "      <td>20181023</td>\n",
       "      <td>201810</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.8027</td>\n",
       "      <td>IDN</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>IDN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Gudang, Jawa Tengah, Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID07</td>\n",
       "      <td>-6.71010</td>\n",
       "      <td>110.947</td>\n",
       "      <td>10171924</td>\n",
       "      <td>20181023</td>\n",
       "      <td>https://www.dealstreetasia.com/stories/indones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>796651935</td>\n",
       "      <td>20181023</td>\n",
       "      <td>201810</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.8027</td>\n",
       "      <td>IDN</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>IDN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10171924</td>\n",
       "      <td>4</td>\n",
       "      <td>Gudang, Jawa Tengah, Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID07</td>\n",
       "      <td>-6.71010</td>\n",
       "      <td>110.947</td>\n",
       "      <td>10171924</td>\n",
       "      <td>20181023</td>\n",
       "      <td>https://www.dealstreetasia.com/stories/indones...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   796649358  20171023  201710  2017  2017.8027  BUS   CORPORATION Unnamed: 7  \\\n",
       "0  796650128  20181023  201810  2018  2018.8027  AFR        AFRICA        AFR   \n",
       "1  796650297  20181023  201810  2018  2018.8027  BUS      INDUSTRY        NaN   \n",
       "2  796650336  20181023  201810  2018  2018.8027  BUS  ENTREPRENEUR        NaN   \n",
       "3  796651934  20181023  201810  2018  2018.8027  IDN     INDONESIA        IDN   \n",
       "4  796651935  20181023  201810  2018  2018.8027  IDN     INDONESIA        IDN   \n",
       "\n",
       "  Unnamed: 8 Unnamed: 9  \\\n",
       "0        NaN        NaN   \n",
       "1        NaN        NaN   \n",
       "2        NaN        NaN   \n",
       "3        NaN        NaN   \n",
       "4        NaN        NaN   \n",
       "\n",
       "                                         ...                                          \\\n",
       "0                                        ...                                           \n",
       "1                                        ...                                           \n",
       "2                                        ...                                           \n",
       "3                                        ...                                           \n",
       "4                                        ...                                           \n",
       "\n",
       "       ID.2  4.1           Manila, Manila, Philippines.1 RP.1  RPD9.1  \\\n",
       "0       NaN    4  Komodo, Indonesia (general), Indonesia   ID    ID00   \n",
       "1       NaN    4          Gudang, Jawa Tengah, Indonesia   ID    ID07   \n",
       "2  10171924    4          Gudang, Jawa Tengah, Indonesia   ID    ID07   \n",
       "3       NaN    4          Gudang, Jawa Tengah, Indonesia   ID    ID07   \n",
       "4  10171924    4          Gudang, Jawa Tengah, Indonesia   ID    ID07   \n",
       "\n",
       "  14.6042.1 120.982.1 -2437894.1  20181023  \\\n",
       "0  -8.58333   119.500   -2683074  20181023   \n",
       "1  -6.71010   110.947   10171924  20181023   \n",
       "2  -6.71010   110.947   10171924  20181023   \n",
       "3  -6.71010   110.947   10171924  20181023   \n",
       "4  -6.71010   110.947   10171924  20181023   \n",
       "\n",
       "  https://www.dealstreetasia.com/stories/chinese-fintech-lenders-philippines-109510/  \n",
       "0  https://www.escape.com.au/news/better-than-bal...                                  \n",
       "1  https://www.dealstreetasia.com/stories/indones...                                  \n",
       "2  https://www.dealstreetasia.com/stories/indones...                                  \n",
       "3  https://www.dealstreetasia.com/stories/indones...                                  \n",
       "4  https://www.dealstreetasia.com/stories/indones...                                  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open first file for sanity check\n",
    "df_awal = pd.read_csv(folder_id + files[9],sep=\"\\t\",encoding='latin-1') # melihat sampel isi data\n",
    "df_awal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan ke MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setetelah di List filenya, kemudian semua file yang ada di D:/GDELT/country/ dimasukkan ke MySQL dengan nama tabel per setiap file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "username = 'root'\n",
    "password = ''\n",
    "database = 'gdelt_content'\n",
    "\n",
    "# Create Connection to database\n",
    "engine = create_engine('mysql+pymysql://'+username+':'+password+'@'+host+':'+port+'/'+database)\n",
    "'''engine = create_engine('mysql+pymysql://root: @localhost:3306/gdelt_content_id')'''\n",
    "\n",
    "def run(sql):\n",
    "    df = pd.read_sql_query(sql, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ID0000.tsv\n",
      "Extracting ID0001.tsv\n",
      "Extracting ID0002.tsv\n",
      "Extracting ID0003.tsv\n",
      "Extracting ID0004.tsv\n",
      "Extracting ID0005.tsv\n",
      "Extracting ID0006.tsv\n",
      "Extracting ID0007.tsv\n",
      "Extracting ID0008.tsv\n",
      "Extracting ID0009.tsv\n"
     ]
    }
   ],
   "source": [
    "# Read header / column names\n",
    "colnames = list(pd.read_excel('CSV.header.fieldids.xlsx', sheet_name='CSV.header.dailyupdates'))\n",
    "\n",
    "for berkas in files:\n",
    "    print('Extracting ' + berkas)\n",
    "    df_satuan = pd.DataFrame()\n",
    "    \n",
    "    # Important: If your ID0000.tsv contains header, you can delete the header\n",
    "    df_satuan = pd.read_csv(folder_id + berkas, sep=\"\\t\", names= colnames, encoding='latin-1')\n",
    "    df_satuan.to_sql(name = berkas, con = engine, if_exists = 'append', index = False) # Memasukkan data ke tabel sesuai dengan file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
